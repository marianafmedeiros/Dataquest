{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# App Stores Dataset Analysis\n",
    "\n",
    "This project is about analyzing data to help a company that builds Android and iOS mobile apps. This company works in building free apps in which there are in-app ads. Their revenue comes from the engagement between the users and those in-app ads. Therefore, the more users that see and engage wih the ads, the better.\n",
    "\n",
    "Our goal in this project is to identify which type of apps are likely to attract more users on Google Play and App Store so the developers can understand the best apps to build.\n",
    "\n",
    "Collecting data for over 4 million apps requires a significant amount of time and money, so we'll try to analyze a sample of the data instead. To avoid spending resources on collecting new data ourselves, we should first try to see if we can find any relevant existing data at no cost. Luckily, these are two data sets that seem suitable for our goals:\n",
    "\n",
    "* A [data set](https://www.kaggle.com/lava18/google-play-store-apps/home) containing data about approximately 10,000 Android apps from Google Play; the data was collected in August 2018.\n",
    "* A [data set](https://www.kaggle.com/ramamet4/app-store-apple-data-set-10k-apps/home) containing data about approximately 7,000 iOS apps from the App Store; the data was collected in July 2017."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Data\n",
    "\n",
    "First, we will define a function that allows us to explore the dataset we chose to analyze. The following function shows us, for instance, some of the data so we can have an idea on how it is organized inside the dataset as well as the number of rows and columns and the name of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_data (dataset, start, end, rows_and_columns = False):\n",
    "    dataset_slice = dataset[start:end]\n",
    "    for row in dataset_slice:\n",
    "        print(row)\n",
    "        print('\\n')\n",
    "        \n",
    "    if rows_and_columns:\n",
    "        print('Number of rows:', len(dataset))\n",
    "        print('Number of columns:', len(dataset[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the function defined, we will open the datasets files that are located in a different directory from the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_opened_file = open('./AppleStore.csv', encoding = 'utf8')\n",
    "android_opened_file = open ('./googleplaystore.csv',  encoding = 'utf8')\n",
    "from csv import reader\n",
    "apple_file = reader(apple_opened_file)\n",
    "android_file = reader(android_opened_file)\n",
    "apple_apps = list(apple_file)\n",
    "android_apps = list (android_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then explore the data with the function `explore_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'id', 'track_name', 'size_bytes', 'currency', 'price', 'rating_count_tot', 'rating_count_ver', 'user_rating', 'user_rating_ver', 'ver', 'cont_rating', 'prime_genre', 'sup_devices.num', 'ipadSc_urls.num', 'lang.num', 'vpp_lic']\n",
      "\n",
      "\n",
      "['1', '281656475', 'PAC-MAN Premium', '100788224', 'USD', '3.99', '21292', '26', '4', '4.5', '6.3.5', '4+', 'Games', '38', '5', '10', '1']\n",
      "\n",
      "\n",
      "['2', '281796108', 'Evernote - stay organized', '158578688', 'USD', '0', '161065', '26', '4', '3.5', '8.2.2', '4+', 'Productivity', '37', '5', '23', '1']\n",
      "\n",
      "\n",
      "['3', '281940292', 'WeatherBug - Local Weather, Radar, Maps, Alerts', '100524032', 'USD', '0', '188583', '2822', '3.5', '4.5', '5.0.0', '4+', 'Weather', '37', '5', '3', '1']\n",
      "\n",
      "\n",
      "['4', '282614216', 'eBay: Best App to Buy, Sell, Save! Online Shopping', '128512000', 'USD', '0', '262241', '649', '4', '4.5', '5.10.0', '12+', 'Shopping', '37', '5', '9', '1']\n",
      "\n",
      "\n",
      "Number of rows: 7198\n",
      "Number of columns: 17\n",
      "\n",
      "\n",
      "['App', 'Category', 'Rating', 'Reviews', 'Size', 'Installs', 'Type', 'Price', 'Content Rating', 'Genres', 'Last Updated', 'Current Ver', 'Android Ver']\n",
      "\n",
      "\n",
      "['Photo Editor & Candy Camera & Grid & ScrapBook', 'ART_AND_DESIGN', '4.1', '159', '19M', '10,000+', 'Free', '0', 'Everyone', 'Art & Design', 'January 7, 2018', '1.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "['Coloring book moana', 'ART_AND_DESIGN', '3.9', '967', '14M', '500,000+', 'Free', '0', 'Everyone', 'Art & Design;Pretend Play', 'January 15, 2018', '2.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "['U Launcher Lite ‚Äì FREE Live Cool Themes, Hide Apps', 'ART_AND_DESIGN', '4.7', '87510', '8.7M', '5,000,000+', 'Free', '0', 'Everyone', 'Art & Design', 'August 1, 2018', '1.2.4', '4.0.3 and up']\n",
      "\n",
      "\n",
      "['Sketch - Draw & Paint', 'ART_AND_DESIGN', '4.5', '215644', '25M', '50,000,000+', 'Free', '0', 'Teen', 'Art & Design', 'June 8, 2018', 'Varies with device', '4.2 and up']\n",
      "\n",
      "\n",
      "Number of rows: 10842\n",
      "Number of columns: 13\n"
     ]
    }
   ],
   "source": [
    "explore_data (apple_apps, 0, 5, True)\n",
    "print ('\\n')\n",
    "explore_data (android_apps, 0, 5, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning Part 01 - Removing Innacurate Data\n",
    "\n",
    "Moving forward, we will perform a simple data cleaning process so we can isolate the data we are actually interested in: **Free apps that are developed towards an English-Speaking Audience.**\n",
    "\n",
    "From this [topic](https://www.kaggle.com/lava18/google-play-store-apps/discussion/66015) in the discussion session from where the data was imported, it was possible to identify an error within the dataset. As we don't know if the user considered or not the header row, we will check if the index provided (10472) is indeed correct.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['App', 'Category', 'Rating', 'Reviews', 'Size', 'Installs', 'Type', 'Price', 'Content Rating', 'Genres', 'Last Updated', 'Current Ver', 'Android Ver']\n",
      "\n",
      "\n",
      "[['Xposed Wi-Fi-Pwd', 'PERSONALIZATION', '3.5', '1042', '404k', '100,000+', 'Free', '0', 'Everyone', 'Personalization', 'August 5, 2014', '3.0.0', '4.0.3 and up'], ['Life Made WI-Fi Touchscreen Photo Frame', '1.9', '19', '3.0M', '1,000+', 'Free', '0', 'Everyone', '', 'February 11, 2018', '1.0.19', '4.0 and up']]\n"
     ]
    }
   ],
   "source": [
    "print(android_apps[0])\n",
    "print ('\\n')\n",
    "print (android_apps[10472:10474])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above, the actual row from the dataset that is missing information (in this case, the \"category\" info) is the row indexed to the 10473. Therefore we will remove this row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before length:  10842\n",
      "After length:  10841\n"
     ]
    }
   ],
   "source": [
    "print( 'Before length: ', len(android_apps))\n",
    "del android_apps[10473]\n",
    "print( 'After length: ', len(android_apps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning Part 02 - Removing Duplicates \n",
    "\n",
    "Furthermore, we will check if there are any duplicates in each of the datasets. For this, we will create a function called `if_duplicates`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def if_duplicates (dataset_name, row_name):\n",
    "    duplicate_apps = []\n",
    "    unique_apps = []\n",
    "\n",
    "    for app in dataset_name[1:]:\n",
    "        name = app[row_name]\n",
    "        if name in unique_apps:\n",
    "            duplicate_apps.append(name)\n",
    "        else:\n",
    "            unique_apps.append(name)\n",
    "        \n",
    "    return [duplicate_apps,unique_apps]\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this function, we will loop through both datasets to identify if there is any duplicates and if so, how many."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of duplicate android apps:   1181\n",
      "\n",
      "\n",
      "Some of the apps are:   ['Quick PDF Scanner + OCR FREE', 'Box', 'Google My Business', 'ZOOM Cloud Meetings', 'join.me - Simple Meetings', 'Box', 'Zenefits', 'Google Ads', 'Google My Business', 'Slack', 'FreshBooks Classic', 'Insightly CRM', 'QuickBooks Accounting: Invoicing & Expenses', 'HipChat - Chat Built for Teams', 'Xero Accounting Software']\n",
      "\n",
      "\n",
      "number of android unique apps:   9659\n",
      "\n",
      "\n",
      "number of apple duplicate apps:   2\n",
      "\n",
      "\n",
      "Some of the apps are:   ['VR Roller Coaster', 'Mannequin Challenge']\n",
      "\n",
      "\n",
      "number of apple unique apps:   7195\n"
     ]
    }
   ],
   "source": [
    "duplicates_android = if_duplicates(android_apps,0)[0]\n",
    "unique_android = if_duplicates(android_apps,0)[1]\n",
    "print (\"number of duplicate android apps:\", \" \", len(duplicates_android))\n",
    "print ('\\n')\n",
    "print (\"Some of the apps are:\", \" \", duplicates_android[:15])\n",
    "print ('\\n')\n",
    "print (\"number of android unique apps:\", \" \", len(unique_android))\n",
    "print ('\\n')\n",
    "duplicates_apple = if_duplicates(apple_apps,2)[0]\n",
    "unique_apple = if_duplicates(apple_apps,2)[1]\n",
    "print (\"number of apple duplicate apps:\", \" \", len(duplicates_apple))\n",
    "print ('\\n')\n",
    "print (\"Some of the apps are:\", \" \", duplicates_apple[:15])\n",
    "print ('\\n')\n",
    "print (\"number of apple unique apps:\", \" \", len(unique_apple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'id', 'track_name', 'size_bytes', 'currency', 'price', 'rating_count_tot', 'rating_count_ver', 'user_rating', 'user_rating_ver', 'ver', 'cont_rating', 'prime_genre', 'sup_devices.num', 'ipadSc_urls.num', 'lang.num', 'vpp_lic']\n",
      "\n",
      "\n",
      "['4000', '952877179', 'VR Roller Coaster', '169523200', 'USD', '0', '107', '102', '3.5', '3.5', '2.0.0', '4+', 'Games', '37', '5', '1', '1']\n",
      "['7579', '1089824278', 'VR Roller Coaster', '240964608', 'USD', '0', '67', '44', '3.5', '4', '0.81', '4+', 'Games', '38', '0', '1', '1']\n"
     ]
    }
   ],
   "source": [
    "print(apple_apps[0])\n",
    "print ('\\n')\n",
    "for app in apple_apps [1:]:\n",
    "    name = app[2]\n",
    "    if name == 'VR Roller Coaster':\n",
    "        print (app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, we have 1181 duplicate android entries and only 2 duplicate apple entries.We will not delete the duplicates randomly. It is better to stay with the most recent entries so we get the most recent data from each app. However, the same app can be present in 2+ different categories (which is relevant for this analysis). Thus, as a criteria, we will maintain the entry with the most reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique apps for android: 9659\n",
      "\n",
      "\n",
      "number of unique apps for apple: 7195\n"
     ]
    }
   ],
   "source": [
    "reviews_max_google = {}\n",
    "\n",
    "for app in android_apps[1:]:\n",
    "    name = app[0]\n",
    "    n_reviews = float(app[3])\n",
    "    \n",
    "    if name in reviews_max_google           and \\\n",
    "    reviews_max_google[name] < n_reviews:\n",
    "        reviews_max_google[name] = n_reviews\n",
    "        \n",
    "    elif name not in reviews_max_google:\n",
    "        reviews_max_google[name]= n_reviews\n",
    "\n",
    "reviews_max_apple = {}\n",
    "\n",
    "for app in apple_apps[1:]:\n",
    "    name = app[2]\n",
    "    n_reviews = float(app[6])\n",
    "    \n",
    "    if name in reviews_max_apple           and \\\n",
    "    reviews_max_apple[name] < n_reviews:\n",
    "        reviews_max_apple[name] = n_reviews\n",
    "        \n",
    "    elif name not in reviews_max_apple:\n",
    "        reviews_max_apple[name]= n_reviews\n",
    "        \n",
    "\n",
    "\n",
    "print ('number of unique apps for android:',len(reviews_max_google))  \n",
    "print('\\n')\n",
    "print ('number of unique apps for apple:',len(reviews_max_apple)) \n",
    "\n",
    "\n",
    "       \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the length of those dictionaries match the expected, we can state that they are reliable. Then, we have dictionaries with only one entry for each app. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to make a list with no duplicate data by performing a data clean process and deleting duplicates from the Android and Apple Apps datasets. We will create, then, two lists that will be useful for us: the `android_clean_dataset` and the `apple_clean_dataset`.\n",
    "\n",
    "We go through the datasets and compare the app name of each entry to `already_added` list so we can keep track of what we have already added and avoid duplicates as some entries may have the same number of reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of apps in the android clean dataset is: 9659\n",
      "\n",
      "\n",
      "number of apps in the apple clean dataset is: 7195\n"
     ]
    }
   ],
   "source": [
    "android_clean_dataset = []\n",
    "already_added = []\n",
    "\n",
    "for app in android_apps[1:]:\n",
    "    name = app[0]\n",
    "    n_reviews = float(app[3])\n",
    "    \n",
    "    if name in reviews_max_google and n_reviews == reviews_max_google[name] and name not in already_added:\n",
    "        android_clean_dataset.append(app)\n",
    "        already_added.append(name)\n",
    "                             \n",
    "                            \n",
    "print( 'number of apps in the android clean dataset is:', len(android_clean_dataset))\n",
    "print ('\\n')\n",
    "apple_clean_dataset = []\n",
    "already_added = []\n",
    "\n",
    "for app in apple_apps[1:]:\n",
    "    name = app[2]\n",
    "    n_reviews = float(app[6])\n",
    "    \n",
    "    if name in reviews_max_apple and n_reviews == reviews_max_apple[name] and name not in already_added:\n",
    "        apple_clean_dataset.append(app)\n",
    "        already_added.append(name)\n",
    "print( 'number of apps in the apple clean dataset is:', len(apple_clean_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning Part 03 - Removing Non-English Apps\n",
    "\n",
    "As we want free apps that are developed towards an **English-Speaking Audience**, we will delete the ones that are made in a different language. For this, we will first build the function `if_english` and then test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def if_english (appname):\n",
    "    for character in appname:\n",
    "        order = ord(character)\n",
    "        if order > 127:\n",
    "             return False\n",
    "            \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print (if_english('Áà±Â•áËâ∫PPS -„ÄäÊ¨¢‰πêÈ¢Ç2„ÄãÁîµËßÜÂâßÁÉ≠Êí≠'))\n",
    "print (if_english('Instagram'))\n",
    "print (if_english('Docs To Go‚Ñ¢ Free Office Suit'))\n",
    "print (if_english('Instachat üòú'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above, the function did not succeed in identifying certain app names. This is because emojis and characters like ‚Ñ¢ fall outside the ASCII range and have corresponding numbers over 127."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128540\n",
      "8482\n"
     ]
    }
   ],
   "source": [
    "print( ord('üòú'))\n",
    "print( ord('‚Ñ¢'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, to minimize data loss, we will only delete apps that have more than three characters that fall outside de ASCII range, modifying our `if_english` function and testing it again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def if_english(appname):\n",
    "    non_ascii = 0\n",
    "    is_english = True\n",
    "    for character in appname:\n",
    "        order = ord(character)\n",
    "        if order > 127:\n",
    "            non_ascii += 1\n",
    "    \n",
    "    if non_ascii > 3:\n",
    "        is_english = False\n",
    "    \n",
    "    return is_english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print (if_english('Áà±Â•áËâ∫PPS -„ÄäÊ¨¢‰πêÈ¢Ç2„ÄãÁîµËßÜÂâßÁÉ≠Êí≠'))\n",
    "print (if_english('Instagram'))\n",
    "print (if_english('Docs To Go‚Ñ¢ Free Office Suit'))\n",
    "print (if_english('Instachat üòú'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this function, we will loop through both datasets to delete all the potential non-english apps and adding the cleaner dataset to the lists `android_english_apps` and `apple_english_apps`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in Google Dataset:  9614\n",
      "Rows in Apple Dataset:  6184\n",
      "\n",
      "\n",
      "[['Photo Editor & Candy Camera & Grid & ScrapBook', 'ART_AND_DESIGN', '4.1', '159', '19M', '10,000+', 'Free', '0', 'Everyone', 'Art & Design', 'January 7, 2018', '1.0.0', '4.0.3 and up'], ['U Launcher Lite ‚Äì FREE Live Cool Themes, Hide Apps', 'ART_AND_DESIGN', '4.7', '87510', '8.7M', '5,000,000+', 'Free', '0', 'Everyone', 'Art & Design', 'August 1, 2018', '1.2.4', '4.0.3 and up']]\n",
      "[['', 'id', 'track_name', 'size_bytes', 'currency', 'price', 'rating_count_tot', 'rating_count_ver', 'user_rating', 'user_rating_ver', 'ver', 'cont_rating', 'prime_genre', 'sup_devices.num', 'ipadSc_urls.num', 'lang.num', 'vpp_lic'], ['1', '281656475', 'PAC-MAN Premium', '100788224', 'USD', '3.99', '21292', '26', '4', '4.5', '6.3.5', '4+', 'Games', '38', '5', '10', '1']]\n"
     ]
    }
   ],
   "source": [
    "android_english_apps =[]\n",
    "apple_english_apps = []\n",
    "\n",
    "for app in android_clean_dataset:\n",
    "    if if_english(app[0]):\n",
    "        android_english_apps.append(app)\n",
    "\n",
    "for app in apple_apps:\n",
    "    if if_english(app[2]):\n",
    "        apple_english_apps.append(app)  \n",
    "\n",
    "print ('Rows in Google Dataset: ', len(android_english_apps))\n",
    "print ('Rows in Apple Dataset: ', len(apple_english_apps))\n",
    "print ('\\n')\n",
    "print (android_english_apps[:2])\n",
    "print (apple_english_apps[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning Part 04 - Removing Non-free Apps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step will be to remove any non-free apps as the free apps are the type that is important to this analysis. We will then create a function for this purpose called `free_apps`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def free_apps(appdata,price_row):\n",
    "    freeapps_data = []\n",
    "    for app in appdata:\n",
    "        price = app[price_row]\n",
    "        if price == '0':\n",
    "            freeapps_data.append(app)\n",
    "    return freeapps_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "android dataset length: 8864\n",
      "apple dataset length: 3222\n"
     ]
    }
   ],
   "source": [
    "freeapps_android = free_apps (android_english_apps,7)\n",
    "freeapps_apple = free_apps (apple_english_apps, 5)\n",
    "print ('android dataset length:',len(freeapps_android))\n",
    "print ('apple dataset length:',len(freeapps_apple))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To confirm the right execution of this function, we will loop through android apps and make another list of free apps but now with the criteria that the sixth row is the string `\"free\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "android dataset length: 8863\n"
     ]
    }
   ],
   "source": [
    "freeandroid = []\n",
    "\n",
    "for app in android_english_apps:\n",
    "    if app[6] == 'Free':\n",
    "        freeandroid.append(app)\n",
    "\n",
    "print (\"android dataset length:\", len(freeandroid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there is a similar result for both criterias so the function defined is a reliable one. There must be a wrong entry but it is not relevant for the final result as there is just one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have:\n",
    "1. Removed inaccurate data\n",
    "2. Removed duplicate app entries\n",
    "3. Removed non-English apps\n",
    "4. Isolated the free apps\n",
    "\n",
    "As stated in the beggining, our aim is to determine the kinds of apps that are likely to attract more users because our revenue is highly influenced by the number of people using our apps. \n",
    "\n",
    "To minimize risks and overhead, our validation strategy for an app idea is comprised of three steps:\n",
    "\n",
    "1. Build a minimal Android version of the app, and add it to Google Play.\n",
    "2. If the app has a good response from users, we develop it further.\n",
    "3. If the app is profitable after six months, we build an iOS version of the app and add it to the App Store.\n",
    "\n",
    "Because our end goal is to add the app on both Google Play and the App Store, we need to find app profiles that are successful on both markets. For instance, a profile that works well for both markets might be a productivity app that makes use of gamification."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
